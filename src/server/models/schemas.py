from typing import List, Optional, Literal, Dict
from pydantic import BaseModel, Field

class UserQuery(BaseModel):
    """Input query from the user."""
    query_text: str = Field(..., description="The user's question.")
    user_role: Optional[str] = Field(None, description="The role of the user asking (e.g., 'developer', 'hr_manager').")

class RoutingDecision(BaseModel):
    """Decision on which agent to route the query to."""
    agent_id: str = Field(..., description="The ID of the agent to route to.")
    agent_name: str = Field(..., description="The name of the agent selected.")
    reasoning: str = Field(..., description="Explanation for why this agent was chosen.")
    confidence: float = Field(..., description="Confidence score between 0.0 and 1.0.")

class SourceChunk(BaseModel):
    """Information about a source chunk used in the response."""
    file_name: str = Field(..., description="Name of the source file.")
    content: str = Field(..., description="The actual text content of the chunk.")
    
class AgentResponse(BaseModel):
    """Response from a specialist agent."""
    answer: str = Field(..., description="The answer generated by the agent.")
    sources: List[str] = Field(default_factory=list, description="List of source document names used.")
    source_chunks: List[SourceChunk] = Field(default_factory=list, description="Detailed source chunks with content.")
    agent_name: str = Field(..., description="Name of the agent that generated the response.")

class AuditResult(BaseModel):
    """Result from the auditor agent."""
    is_safe: bool = Field(..., description="Whether the response is safe and tone-appropriate.")
    feedback: str = Field(..., description="Feedback on the response tone and content.")
    final_answer: str = Field(..., description="The final, possibly revised, answer to be shown to the user.")
    politeness_score: float = Field(..., description="Score from 0.0 to 1.0 indicating how polite the response is.", ge=0.0, le=1.0)
    correctness_score: float = Field(..., description="Score from 0.0 to 1.0 indicating how correct/accurate the response is.", ge=0.0, le=1.0)
    confidence_score: float = Field(..., description="Score from 0.0 to 1.0 indicating confidence in the response.", ge=0.0, le=1.0)
